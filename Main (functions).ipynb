{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Importing all libraries used throughout the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_vanguard as vd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Importing data frames, analyzing and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 - Importing Clients Dataframe (df_final_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_demo = vd.import_dataframe()\n",
    "df_final_demo\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 Exploring the Dataframe's columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Display basic information about the dataset*, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Displaying information about **clnt_tenure_yr** (client tenure in years), as well as plotting a histogram to visualize the column's values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Displaying information about **clnt_age** (client age), as well as plotting a histogram to visualize the column's values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Displaying information about **gendr** (gender), as well as creating a pie chart to visualize the column's values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Displaying iformation about **num_accounts** (number of accounts), as well as creating a pie chart and histogram to visualize the column's values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Displaying iformation about **bal** (balance)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Displaying iformation about **logons_6_mnth** (log on in the past 6 months), as well as creating a histogram to visualize the column's values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd.analyze_dataframe(df_final_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.3 - Analyzing Client Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a new column to visualize the total tenure in months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we will categorize the the clients based on their total tenure (in months). They can either be **New** or **Long Standing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, it is important to know whether the clients are **young** or **old**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_demo = vd.analyze_client_demographics(df_final_demo)\n",
    "df_final_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.3 - Identifying Primary Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd.identify_primary_clients(df_final_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.4 Cleaning df_final_demo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will take a look at which columns are completly empty (except for client_id, whic does not have any null values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we will remove all these rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will take a look a the types of each column and make adjustments if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_demo=vd.clean_dataframe(df_final_demo)\n",
    "df_final_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 Importing DataFrame Part 1 which provides information about the visits to Vanguard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt1 = vd.import_and_check_dataframe_part1()\n",
    "df_pt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't any null values, so we do not have to clean anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1 - Importing DataFrame Part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt2 = vd.import_and_check_dataframe_part2()\n",
    "display(df_pt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.2 - Merging the Twin Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Part 2 is an extension to DataFrame Part 1; therefore, they should be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = vd.merge_dataframes(df_pt1, df_pt2)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.1 - Importing Data Frame about the different groups of clients (Test/Control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to determine the **size** of each of the groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the amount of **null values** in the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_experiment = vd.import_and_analyze_experiment_clients()\n",
    "df_final_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(df_final_demo, df, how=\"left\", on = \"client_id\")\n",
    "\n",
    "variation_df = pd.merge(new_df, df_final_experiment_clients, on = \"client_id\", how=\"inner\") # We are using an inner join bc we do not care about client's that did not go thru the process\n",
    "variation_df.reset_index()\n",
    "variation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = variation_df[variation_df[\"Variation\"] == \"Control\"]\n",
    "test_df = variation_df[variation_df[\"Variation\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Determining KPI's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze Time Spent on Each Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date_time to datetime format\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by visit_id and date_time\n",
    "df = df.sort_values(by=['visit_id', 'date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time spent on each step\n",
    "df['time_spent'] = df.groupby('visit_id')['date_time'].diff().dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in time_spent with 0 for the first step\n",
    "df['time_spent'] = df['time_spent'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average time spent on each step\n",
    "time_spent_summary = df.groupby('process_step')['time_spent'].mean().reset_index()\n",
    "print(\"Average Time Spent on Each Step:\")\n",
    "print(time_spent_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the average time spent on each step\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='process_step', y='time_spent', data=time_spent_summary, palette='viridis')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Average Time Spent on Each Step')\n",
    "plt.xlabel('Process Step')\n",
    "plt.ylabel('Average Time Spent (seconds)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Calculate session duration for each visit_id\n",
    "session_durations = variation_df.groupby('visit_id')['time_spent'].sum().reset_index()\n",
    "\n",
    "# Merge with the original data to get the Variation labels\n",
    "df_merged = session_durations.merge(variation_df[['visit_id', 'Variation']].drop_duplicates(), on='visit_id')\n",
    "\n",
    "# Separate the data into control and test groups\n",
    "control_group = df_merged[df_merged['Variation'] == 'Control']['time_spent']\n",
    "test_group = df_merged[df_merged['Variation'] == 'Test']['time_spent']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = ttest_ind(test_group, control_group, alternative='greater')\n",
    "\n",
    "# Output the results\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. Clients using the new UI have significantly longer session durations.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference in session durations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_step_counts = df['process_step'].value_counts()\n",
    "process_step_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each process step\n",
    "process_step_counts = df['process_step'].value_counts()\n",
    "\n",
    "# Plot a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "process_step_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Process Steps')\n",
    "plt.xlabel('Process Step')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df.dropna(subset=\"Variation\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of sessions for each group\n",
    "total_sessions = variation_df.groupby('Variation')['visit_id'].nunique().reset_index(name='total_sessions')\n",
    "\n",
    "# Filter the data to only include rows where process_step is \"confirm\"\n",
    "confirm_steps = variation_df[variation_df['process_step'] == 'confirm']\n",
    "\n",
    "# Count the number of sessions that reached the \"confirm\" step for each group\n",
    "confirm_sessions = confirm_steps.groupby('Variation')['visit_id'].nunique().reset_index(name='confirm_sessions')\n",
    "\n",
    "#Merge total sessions with confirm sessions\n",
    "completion_data = pd.merge(total_sessions, confirm_sessions, on='Variation')\n",
    "\n",
    "# Calculate the completion rate\n",
    "completion_data['completion_rate'] = (completion_data['confirm_sessions'] / completion_data['total_sessions']) * 100\n",
    "\n",
    "print(completion_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a bar chart\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.barplot(x='Variation', y='completion_rate', data=completion_data, palette='Set2')\n",
    "plt.title('Completion Rate by Variation')\n",
    "plt.xlabel('Variation')\n",
    "plt.ylabel('Completion Rate (%)')\n",
    "plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the observed increase in completion rate\n",
    "completion_rate_control = completion_data.loc[completion_data['Variation'] == 'Control', 'completion_rate'].values[0]\n",
    "completion_rate_test = completion_data.loc[completion_data['Variation'] == 'Test', 'completion_rate'].values[0]\n",
    "observed_increase = completion_rate_test - completion_rate_control\n",
    "print(f\"Observed Increase in Completion Rate: {observed_increase:.2f}%\")\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "confirm_sessions_control = 16046\n",
    "total_sessions_control = 32189\n",
    "confirm_sessions_test = 21731\n",
    "total_sessions_test = 37136\n",
    "\n",
    "# Create the contingency table\n",
    "contingency_table = np.array([\n",
    "    [confirm_sessions_control, total_sessions_control - confirm_sessions_control],\n",
    "    [confirm_sessions_test, total_sessions_test - confirm_sessions_test]\n",
    "])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the test statistic and p-value\n",
    "print(f\"Chi-Squared Statistic: {chi2_stat:.2f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")\n",
    "\n",
    "threshold = 5.0  # 5% threshold\n",
    "if observed_increase >= threshold and p_value < 0.05:\n",
    "    print(\"The observed increase in completion rate meets or exceeds the 5% threshold and is statistically significant.\")\n",
    "else:\n",
    "    print(\"The observed increase in completion rate does not meet the 5% threshold or is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amoutn of people per group.\n",
    "variation_counts = variation_df[\"Variation\"].value_counts()\n",
    "variation_counts.plot(kind=\"bar\", color = \"lightskyblue\" )\n",
    "plt.xlabel(\"Group\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(control_df.client_id.count(),test_df.client_id.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to calculate time spent on each step\n",
    "# def calculate_step_duration(df):\n",
    "#     # Ensure 'date_time' is sorted within each user session\n",
    "#     df = df.sort_values(by=['client_id', 'visitor_id', 'date_time'])\n",
    "    \n",
    "#     # Calculate the time spent on each step by finding the difference between consecutive steps\n",
    "#     df['next_step_time'] = df.groupby(['client_id', 'visitor_id'])['date_time'].shift(-1)\n",
    "#     df['time_spent'] = (df['next_step_time'] - df['date_time']).dt.total_seconds()\n",
    "    \n",
    "#     # Drop rows where 'time_spent' is NaN (e.g., the last step in each session)\n",
    "#     df = df.dropna(subset=['time_spent'])\n",
    "    \n",
    "#     # Calculate the average duration spent on each step\n",
    "#     avg_duration_per_step = df.groupby('process_step')['time_spent'].mean().reset_index()\n",
    "#     avg_duration_per_step.columns = ['process_step', 'avg_duration_seconds']\n",
    "    \n",
    "#     return avg_duration_per_step\n",
    "\n",
    "# # Apply the function\n",
    "# average_duration_per_step = calculate_step_duration(variation_df)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Average Duration Spent on Each Step (in seconds):\")\n",
    "# print(average_duration_per_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(x='process_step', y='avg_duration_seconds', data=average_duration_per_step, palette='viridis')\n",
    "# plt.title('Average Duration Spent on Each Step (in seconds)')\n",
    "# plt.xlabel('Process Step')\n",
    "# plt.ylabel('Average Duration (seconds)')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # General function to calculate time spent on each step\n",
    "# def calculate_step_duration(df):\n",
    "#     # Ensure 'date_time' is sorted within each user session\n",
    "#     df = df.sort_values(by=['client_id', 'visitor_id', 'date_time'])\n",
    "    \n",
    "#     # Calculate the time spent on each step by finding the difference between consecutive steps\n",
    "#     df['next_step_time'] = df.groupby(['client_id', 'visitor_id'])['date_time'].shift(-1)\n",
    "#     df['time_spent'] = (df['next_step_time'] - df['date_time']).dt.total_seconds()\n",
    "    \n",
    "#     # Drop rows where 'time_spent' is NaN (e.g., the last step in each session)\n",
    "#     df = df.dropna(subset=['time_spent'])\n",
    "    \n",
    "#     # Calculate the average duration spent on each step\n",
    "#     avg_duration_per_step = df.groupby('process_step')['time_spent'].mean().reset_index()\n",
    "#     avg_duration_per_step.columns = ['process_step', 'avg_duration_seconds']\n",
    "    \n",
    "#     return avg_duration_per_step\n",
    "\n",
    "# # Apply the function to control and test dataframes\n",
    "# average_duration_per_step_control = calculate_step_duration(control_df)\n",
    "# average_duration_per_step_test = calculate_step_duration(test_df)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Average Duration Spent on Each Step (Control Group) (in seconds):\")\n",
    "# print(average_duration_per_step_control)\n",
    "\n",
    "# print(\"Average Duration Spent on Each Step (Test Group) (in seconds):\")\n",
    "# print(average_duration_per_step_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'variation_df' is your DataFrame and it includes 'date_time' and 'process_step' columns\n",
    "control_df = variation_df[variation_df[\"Variation\"] == \"Control\"]\n",
    "test_df = variation_df[variation_df[\"Variation\"] == \"Test\"]\n",
    "\n",
    "# General function to calculate time spent on each step\n",
    "def calculate_step_duration(df):\n",
    "    # Ensure 'date_time' is sorted within each user session\n",
    "    df = df.sort_values(by=['client_id', 'visitor_id', 'date_time'])\n",
    "    \n",
    "    # Calculate the time spent on each step by finding the difference between consecutive steps\n",
    "    df['next_step_time'] = df.groupby(['client_id', 'visitor_id'])['date_time'].shift(-1)\n",
    "    df['time_spent'] = (df['next_step_time'] - df['date_time']).dt.total_seconds()\n",
    "    \n",
    "    # Drop rows where 'time_spent' is NaN (e.g., the last step in each session)\n",
    "    df = df.dropna(subset=['time_spent'])\n",
    "    \n",
    "    # Calculate the average duration spent on each step\n",
    "    avg_duration_per_step = df.groupby('process_step')['time_spent'].mean().reset_index()\n",
    "    avg_duration_per_step.columns = ['process_step', 'avg_duration_seconds']\n",
    "    \n",
    "    return avg_duration_per_step\n",
    "\n",
    "# Apply the function to control and test dataframes\n",
    "average_duration_per_step_control = calculate_step_duration(control_df)\n",
    "average_duration_per_step_test = calculate_step_duration(test_df)\n",
    "\n",
    "# Add a column to distinguish between control and test group\n",
    "average_duration_per_step_control['Group'] = 'Control'\n",
    "average_duration_per_step_test['Group'] = 'Test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both dataframes\n",
    "combined_df = pd.concat([average_duration_per_step_control, average_duration_per_step_test])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create separate palettes for control and test groups\n",
    "palette = {'Control': 'skyblue', 'Test': 'coral'}\n",
    "\n",
    "# Create a bar plot using Seaborn\n",
    "sns.barplot(x='process_step', y='avg_duration_seconds', hue='Group', data=combined_df, palette=palette)\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Average Duration Spent on Each Step by Group (in seconds)')\n",
    "plt.xlabel('Process Step')\n",
    "plt.ylabel('Average Duration (seconds)')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have DataFrames `test_df` and `control_df` with a column 'process_step'\n",
    "\n",
    "# Count the occurrences of each unique value in the 'process_step' column for both DataFrames\n",
    "process_step_counts_test = test_df['process_step'].value_counts().rename('Test')\n",
    "process_step_counts_control = control_df['process_step'].value_counts().rename('Control')\n",
    "\n",
    "# Normalize the counts by the total number of entries in each group\n",
    "total_test = len(test_df)\n",
    "total_control = len(control_df)\n",
    "\n",
    "normalized_test_counts = process_step_counts_test / total_test\n",
    "normalized_control_counts = process_step_counts_control / total_control\n",
    "\n",
    "# Combine the normalized counts into a single DataFrame\n",
    "combined_counts = pd.concat([normalized_test_counts, normalized_control_counts], axis=1).fillna(0)\n",
    "\n",
    "# Plot a bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "combined_counts.plot(kind='bar', color=['red', 'skyblue'], width=0.8)\n",
    "plt.title('Proportional Distribution of Process Steps (Test vs Control Group)')\n",
    "plt.xlabel('Process Step')\n",
    "plt.ylabel('Proportion')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Rates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sort the data by client_id, visit_id, and date_time to trace the usersâ€™ navigation sequence accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by client_id, visit_id, and date_time\n",
    "variation_df = variation_df.sort_values(by=['client_id', 'visitor_id', 'date_time'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Convert time_period to a numeric type: We need to convert time_period to a numeric type if it's not already one, and ensure prev_step is also numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'time_period' is numeric\n",
    "# variation_df['time_period'] = pd.to_numeric(variation_df['time_period'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the frequency of backward navigations for each user in both control and test groups.\n",
    "Compare the error rates between the two groups to assess if the new UI design reduces or increases errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating prev_step:\n",
    "\n",
    "Operation: df.groupby(['client_id', 'visitor_id'])['time_period'].shift(1)\n",
    "Purpose: This groups the data by client_id and visitor_id, then shifts the time_period column by one position to get the previous step for each user session.\n",
    "Result: A new column prev_step that shows the previous time_period for each step.\n",
    "\n",
    "Calculating is_backward:\n",
    "\n",
    "Operation: df.apply(lambda row: row['time_period'] < row['prev_step'] if pd.notnull(row['prev_step']) else False, axis=1)\n",
    "Purpose: For each row, compare the current time_period with prev_step. If prev_step is not NaN, check if the current time_period is less than prev_step, indicating a backward navigation. If prev_step is NaN, set is_backward to False.\n",
    "\n",
    "Result: A new column is_backward that is True if a backward navigation occurred, otherwise False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variation_df[['client_id', 'visitor_id', 'visit_id', 'date_time', 'prev_step','Variation', 'is_backward','process_step','step_index','prev_step_index', 'is_back_track']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variation_df['is_back_track'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new column with the mapped values\n",
    "mapping = { 'start': 0, 'step_1': 1, 'step_2': 2, 'step_3': 3, 'confirm': 4 } \n",
    "variation_df['step_index'] = variation_df['process_step'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df.sort_values(by=['visit_id', 'date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df['prev_step_index'] = variation_df.groupby('visit_id')['step_index'].shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect backward navigation\n",
    "variation_df['is_back_track'] = variation_df['prev_step_index'] > variation_df['step_index'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated error rates by grouping the data by the variation column and computing the mean of the is_backward column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error rates\n",
    "error_rates = variation_df.groupby('Variation')['is_back_track'].mean()\n",
    "\n",
    "print(\"Error Rates:\")\n",
    "print(error_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform statistical tests (e.g., chi-square test) to determine if the difference in error rates between the control and test groups is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis (e.g., chi-square test)\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(variation_df['Variation'], variation_df['is_back_track'])\n",
    "\n",
    "chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-Square Test:\\nChi2: {chi2}\\np-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Calculate session duration for each visit_id\n",
    "session_durations = variation_df.groupby('visit_id')['time_spent'].sum().reset_index()\n",
    "\n",
    "# Merge with the original data to get the Variation labels\n",
    "df_merged = session_durations.merge(variation_df[['visit_id', 'Variation']].drop_duplicates(), on='visit_id')\n",
    "\n",
    "# Separate the data into control and test groups\n",
    "control_group = df_merged[df_merged['Variation'] == 'Control']['time_spent']\n",
    "test_group = df_merged[df_merged['Variation'] == 'Test']['time_spent']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = ttest_ind(test_group, control_group, alternative='greater')\n",
    "\n",
    "# Output the results\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. Clients using the new UI have significantly longer session durations.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference in session durations.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df.Variation.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "df_merged['group'] = np.where(df_merged['Variation'] == 'Test', 'Test Group', 'Control Group')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='group', y='time_spent', data=df_merged, palette='Set2')\n",
    "\n",
    "plt.title('Session Durations: Control vs. Test Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Session Duration (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_merged is already defined and has the necessary data\n",
    "df_merged['group'] = np.where(df_merged['Variation'] == 'Test', 'Test Group', 'Control Group')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(x='group', y='time_spent', data=df_merged, hue='group', palette='Set2')\n",
    "\n",
    "plt.title('Session Durations: Control vs. Test Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Session Duration (seconds)')\n",
    "plt.legend(title='Group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze error rates by different segments (e.g., client tenure, age, gender, number of accounts, balance) to identify if specific groups are more prone to errors.\n",
    "This can help tailor future improvements or targeted interventions for specific client segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation analysis (example by client tenure)\n",
    "segmentation_analysis = variation_df.groupby(['Variation', 'clnt_tenure_yr'])['is_back_track'].mean().unstack()\n",
    "print(\"Segmentation Analysis by Client Tenure:\")\n",
    "print(segmentation_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach will help you understand how the new UI affects user behavior, specifically focusing on error rates indicated by backward navigation. The analysis will also provide insights into which segments of users are most affected, enabling more targeted improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index for plotting\n",
    "segmentation_analysis_reset = segmentation_analysis.reset_index()\n",
    "\n",
    "# Melt the DataFrame to long format for easier plotting with seaborn\n",
    "segmentation_analysis_melted = segmentation_analysis_reset.melt(id_vars='Variation', var_name='Client Tenure (years)', value_name='Backtrack Rate')\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(16, 7))\n",
    "sns.barplot(x='Client Tenure (years)', y='Backtrack Rate', hue='Variation', data=segmentation_analysis_melted, palette='viridis')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Backtrack Rate by Client Tenure and Variation')\n",
    "plt.xlabel('Client Tenure (years)')\n",
    "plt.ylabel('Mean Backtrack Rate')\n",
    "plt.legend(title='Variation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization \n",
    "sns.barplot(x='Variation', y='is_back_track', data=variation_df)\n",
    "plt.title('Error Rates by Variation')\n",
    "plt.xlabel('Variation')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Time Spent on Each Step: Calculate the difference between the timestamps of consecutive steps for each user session.\n",
    "Aggregate the Time Spent by Step: Average these durations for each step across all user sessions.\n",
    "\n",
    "Create next_step_time: Use shift(-1) to get the timestamp of the next step within each user session.\n",
    "Calculate time_spent: Find the difference between next_step_time and date_time, then convert this to seconds.\n",
    "\n",
    "Drop Rows with NaN time_spent:\n",
    "Remove rows where time_spent is NaN, which would occur for the last step of each session since there is no next step to compare.\n",
    "Calculate Average Duration:\n",
    "\n",
    "Group by process_step and compute the mean of time_spent for each step.\n",
    "Reset the index and rename columns for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df.to_csv('variation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE KPIS ARE : Completion rate, error rate, time spent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vanguard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
